{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8cc4a0-8921-4de5-bce7-938027060746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install librosa numpy pandas scikit-learn tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709940ef-b94c-4785-a929-5efa7fcd96a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47c6226-e56d-40d0-9495-9415b112b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e6f3a6-451b-4d73-9758-26fc3d45b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be22084-d465-461e-bf21-1d1e34c14f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b2d746-f22a-4418-b6c2-8ac86727a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './track-2-audio-identification-quest/training_split/training_split'\n",
    "test_dir = './track-2-audio-identification-quest/testing_split/testing_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e888bd16-2182-4445-a60f-3b9e92274197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_files(dir_name):\n",
    "    list_of_files = os.listdir(dir_name)\n",
    "    all_files = []\n",
    "    for entry in list_of_files:\n",
    "        full_path = os.path.join(dir_name, entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            all_files.extend(get_list_of_files(full_path))\n",
    "        else:\n",
    "            all_files.append(full_path)\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf6916e8-27e2-4b12-afa1-4e79ac9421b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 1453\n",
      "Number of testing files: 637\n"
     ]
    }
   ],
   "source": [
    "# Get list of files\n",
    "train_files = get_list_of_files(train_dir)\n",
    "test_files = get_list_of_files(test_dir)\n",
    "\n",
    "print(f\"Number of training files: {len(train_files)}\")\n",
    "print(f\"Number of testing files: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f5de90c-9b36-4d86-8073-72447cbda4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio sample shape: (441000,)\n",
      "Sample rate: 44100\n"
     ]
    }
   ],
   "source": [
    "# Load a sample audio file\n",
    "sample_file = train_files[0]  # Just picking the first training file for now\n",
    "audio, sr = librosa.load(sample_file, sr=None)  # sr=None to keep the original sample rate\n",
    "\n",
    "print(f\"Audio sample shape: {audio.shape}\")\n",
    "print(f\"Sample rate: {sr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb4da23-118c-445c-bb74-3f850f71348c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training features shape: (1453, 40)\n",
      "Augmented training features shape: (1453, 40)\n",
      "Combined training features shape: (2906, 40)\n",
      "Testing features shape: (637, 40)\n"
     ]
    }
   ],
   "source": [
    "def extract_mfcc(file_path, n_mfcc=40):\n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # Extract MFCC features\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfccs, axis=1)  # Averaging over time\n",
    "\n",
    "def extract_mfcc_with_augmentation(file_path, n_mfcc=40):\n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Apply random augmentations (pitch shift or time stretch)\n",
    "    if random.choice([True, False]):\n",
    "        audio = librosa.effects.pitch_shift(y=audio, sr=sr, n_steps=random.uniform(-2, 2))\n",
    "    if random.choice([True, False]):\n",
    "        audio = librosa.effects.time_stretch(y=audio, rate=random.uniform(0.8, 1.2))\n",
    "\n",
    "    # Extract MFCC features\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfccs, axis=1)  # Averaging over time\n",
    "\n",
    "def extract_features_from_files(file_paths, feature_extractor, augment=False):\n",
    "    features = []\n",
    "    for file_path in file_paths:\n",
    "        # Apply augmentation if specified\n",
    "        if augment:\n",
    "            feature = feature_extractor(file_path)\n",
    "        else:\n",
    "            feature = feature_extractor(file_path)\n",
    "        features.append(feature)\n",
    "    return np.array(features)\n",
    "\n",
    "# Extract features for training files with augmentation\n",
    "X_train_augmented = extract_features_from_files(train_files, extract_mfcc_with_augmentation, augment=True)\n",
    "\n",
    "# Extract features for training files without augmentation (original training data)\n",
    "X_train_original = extract_features_from_files(train_files, extract_mfcc, augment=False)\n",
    "\n",
    "# Combine original and augmented data\n",
    "X_train = np.concatenate([X_train_original, X_train_augmented])\n",
    "\n",
    "# Extract features for testing files without augmentation\n",
    "X_test = extract_features_from_files(test_files, extract_mfcc, augment=False)\n",
    "\n",
    "# Print the shape of the features\n",
    "print(f\"Original training features shape: {X_train_original.shape}\")\n",
    "print(f\"Augmented training features shape: {X_train_augmented.shape}\")\n",
    "print(f\"Combined training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55cffa57-f858-4d3e-ab39-129e39f7a06f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_labels_from_filename(filename):\n",
    "    # Example filename: '132_70_female.wav'\n",
    "    print(f\"Processing filename:{filename}\")\n",
    "    match = re.search(r'(\\d+)_([\\d]+)_(male|female)_(\\d+)\\.wav', filename)\n",
    "    if match:\n",
    "        age = int(match.group(2))\n",
    "        gender = match.group(3)\n",
    "        \n",
    "        # Determine age label\n",
    "        if age <= 15:\n",
    "            age_label = 0\n",
    "        elif 16 <= age <= 40:\n",
    "            age_label = 1\n",
    "        else:\n",
    "            age_label = 2\n",
    "        \n",
    "        # Determine gender label\n",
    "        gender_label = 0 if gender == 'male' else 1\n",
    "        \n",
    "        return age_label, gender_label\n",
    "    else:\n",
    "        raise ValueError(\"Filename does not match expected format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c828201d-cf27-4708-b3be-368ac13674bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels_from_files(file_paths):\n",
    "    age_labels = []\n",
    "    gender_labels = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            age_label, gender_label = extract_labels_from_filename(os.path.basename(file_path))\n",
    "            age_labels.append(age_label)\n",
    "            gender_labels.append(gender_label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            \n",
    "    return np.array(age_labels), np.array(gender_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890f648-1a82-4769-8900-0b0e7786d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract labels for training files (labels are the same for both original and augmented data)\n",
    "y_train_age, y_train_gender = extract_labels_from_files(train_files)\n",
    "\n",
    "# Print shapes of labels\n",
    "print(f\"Training age labels shape: {y_train_age.shape}\")\n",
    "print(f\"Training gender labels shape: {y_train_gender.shape}\")\n",
    "\n",
    "# Combine original and augmented features\n",
    "X_train = np.concatenate([X_train_original, X_train_augmented])\n",
    "\n",
    "# Since the labels remain the same, concatenate the labels twice (once for original, once for augmented)\n",
    "y_train_age_combined = np.concatenate([y_train_age, y_train_age])\n",
    "y_train_gender_combined = np.concatenate([y_train_gender, y_train_gender])\n",
    "\n",
    "# Split the combined training data into training and validation sets\n",
    "X_train_final, X_val, y_train_age_final, y_val_age, y_train_gender_final, y_val_gender = train_test_split(\n",
    "    X_train, y_train_age_combined, y_train_gender_combined, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Print shapes of the final training and validation sets\n",
    "print(f\"Training features shape: {X_train_final.shape}\")\n",
    "print(f\"Validation features shape: {X_val.shape}\")\n",
    "print(f\"Training age labels shape: {y_train_age_final.shape}\")\n",
    "print(f\"Validation age labels shape: {y_val_age.shape}\")\n",
    "print(f\"Training gender labels shape: {y_train_gender_final.shape}\")\n",
    "print(f\"Validation gender labels shape: {y_val_gender.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "370e13ed-c543-4f01-907c-0ba4712c5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a11bbba-e23c-4f1a-8136-58340253500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model\n",
    "input_layer = Input(shape=(X_train.shape[1], 1))\n",
    "x = Conv1D(32, 3, activation='relu')(input_layer)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# Define two separate output layers\n",
    "age_output = Dense(3, activation='softmax', name='age_output')(x)\n",
    "gender_output = Dense(2, activation='softmax', name='gender_output')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[age_output, gender_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss={'age_output': 'sparse_categorical_crossentropy', 'gender_output': 'sparse_categorical_crossentropy'},\n",
    "    metrics={'age_output': 'accuracy', 'gender_output': 'accuracy'}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcd1a852-44fd-4100-9aec-a7e1b6f7f244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">38,976</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ age_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gender_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m608\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m38,976\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ age_output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 │             \u001b[38;5;34m195\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gender_output (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │             \u001b[38;5;34m130\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,429</span> (154.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,429\u001b[0m (154.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,429</span> (154.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,429\u001b[0m (154.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16fc6290-0385-4cb7-816d-96186321102b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2906, 40, 1)\n",
      "(582, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "#reshaping\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print(X_train.shape)  \n",
    "print(X_val.shape)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f2184-ba92-4003-ae56-5cbda9bfcf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine original and augmented features (should have 2906 samples now)\n",
    "X_train = np.concatenate([X_train_original, X_train_augmented])\n",
    "\n",
    "# Since labels remain the same for both original and augmented data, concatenate the labels twice\n",
    "y_train_age_combined = np.tile(y_train_age, 2)  # Duplicating the labels to match augmented data\n",
    "y_train_gender_combined = np.tile(y_train_gender, 2)\n",
    "\n",
    "# Check the sizes after concatenation\n",
    "print(f\"Training features shape after augmentation: {X_train.shape}\")\n",
    "print(f\"Training age labels shape after augmentation: {y_train_age_combined.shape}\")\n",
    "print(f\"Training gender labels shape after augmentation: {y_train_gender_combined.shape}\")\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train_final, X_val, y_train_age_final, y_val_age, y_train_gender_final, y_val_gender = train_test_split(\n",
    "    X_train, y_train_age_combined, y_train_gender_combined, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check the sizes of the final training and validation sets\n",
    "print(f\"Final training features shape: {X_train_final.shape}\")\n",
    "print(f\"Validation features shape: {X_val.shape}\")\n",
    "print(f\"Final training age labels shape: {y_train_age_final.shape}\")\n",
    "print(f\"Validation age labels shape: {y_val_age.shape}\")\n",
    "print(f\"Final training gender labels shape: {y_train_gender_final.shape}\")\n",
    "print(f\"Validation gender labels shape: {y_val_gender.shape}\")\n",
    "\n",
    "# Model training (should work now as all shapes match)\n",
    "history = model.fit(\n",
    "    X_train_final, \n",
    "    {'age_output': y_train_age_final, 'gender_output': y_train_gender_final},\n",
    "    epochs=200,  \n",
    "    batch_size=32,  \n",
    "    validation_data=(X_val, {'age_output': y_val_age, 'gender_output': y_val_gender}),\n",
    "    verbose=1  # Set to 1 to see progress during training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b823736-b223-4a90-8c08-a4a2a1a9a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for test files\n",
    "X_test = extract_features_from_files(test_files, extract_mfcc)\n",
    "X_test = scaler.transform(X_test)  # Apply the same scaling as training data\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))  # Reshape for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d886d75-16ef-49b1-807f-378761d4de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test files: 637\n",
      "Shape of X_test: (637, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of test files: {len(test_files)}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "184860fc-4fa2-4480-8770-dce2d97b9531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test: (637, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b54f36e2-085f-4dbd-bd84-9e985add604a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test, batch_size=32)   #637/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5518bd0-08c0-4ae8-ad65-aa6ca80ace3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 1 2 0 2 2 1 2]\n",
      "[1 0 1 1 0 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# #not using for now\n",
    "# # Define thresholds for fallback logic\n",
    "# lower_bound_threshold = 0 # Lower bound for confidence\n",
    "\n",
    "# Extract probabilities for each sample\n",
    "predicted_age_probs = predictions[0]  # Probabilities for age groups\n",
    "predicted_gender_probs = predictions[1]\n",
    "# Initialize an array for predicted labels\n",
    "predicted_age_labels = np.argmax(predicted_age_probs, axis=1)\n",
    "predicted_gender_labels = np.argmax(predicted_gender_probs, axis=1)\n",
    "\n",
    "# # Apply fallback mechanism so 0 can be included now,\n",
    "# for i, probs in enumerate(predicted_age_probs):\n",
    "#     if np.max(probs) < lower_bound_threshold:\n",
    "#         predicted_age_labels[i] = 0  # Assign to age group 0 if below threshold\n",
    "\n",
    "\n",
    "# Print some predictions to check\n",
    "print(predicted_age_labels[:10])  # Print first 10 predictions\n",
    "print(predicted_gender_labels[:10])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7b5f0-cfaf-496a-86a5-7a2e18b40803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold function\n",
    "def threshold_gender_prediction(gender_probs, threshold=0.9):\n",
    "    print(f\"Gender probabilities: {gender_probs}\")  # Debugging line\n",
    "    return 0 if gender_probs[1] < threshold else 1\n",
    "\n",
    "# Extract probabilities from model predictions\n",
    "gender_probs = model.predict(X_test)[1]  # Ensure this is the correct output for gender\n",
    "\n",
    "# Apply the threshold to each probability set\n",
    "gender_predictions = [threshold_gender_prediction(probs) for probs in gender_probs]\n",
    "\n",
    "# Print some of the predictions for debugging\n",
    "print(\"Gender predictions with threshold:\")\n",
    "for i in range(5):  # Print first 5 samples\n",
    "    print(f\"Sample {i}: Gender probs: {gender_probs[i]}, Prediction: {gender_predictions[i]}\")\n",
    "\n",
    "# Example DataFrame update\n",
    "df = pd.DataFrame({\n",
    "    'File_name': [os.path.splitext(os.path.basename(file))[0] for file in test_files],\n",
    "    'Age_group': predicted_age_labels,\n",
    "    'Gender': ['Male' if gender == 0 else 'Female' for gender in gender_predictions]\n",
    "})\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c36212ed-cf1a-4114-8fb6-6d6643499bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in DataFrame: 637\n",
      "  File_name  Age_group  Gender\n",
      "0         1          2    Male\n",
      "1        10          2    Male\n",
      "2      1000          2    Male\n",
      "3       106          1  Female\n",
      "4       107          2    Male\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'File_name': [os.path.splitext(os.path.basename(file))[0] for file in test_files],\n",
    "    'Age_group': predicted_age_labels,\n",
    "    'Gender': ['Male' if gender == 0 else 'Female' for gender in gender_predictions]\n",
    "})\n",
    "\n",
    "# Print DataFrame details\n",
    "print(f\"Number of rows in DataFrame: {len(df)}\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f3c98-e305-4952-85d4-7af3b3b53ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = 'lala.csv'\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "#finished !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216053b9-9f26-45b6-bd84-b103e36b8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_age_probs[:10])  # Print probabilities for the first 10 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eeaa5bd5-a171-43b5-afb1-3cb420de8a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filename for index 0 is: 1.wav\n"
     ]
    }
   ],
   "source": [
    "# Create a list of test file names\n",
    "test_file_names = [os.path.basename(file) for file in test_files]\n",
    "\n",
    "# Define the index you want to check\n",
    "sample_index = 0# For example, if the index is 1\n",
    "\n",
    "# Get the filename for that index\n",
    "filename = test_file_names[sample_index]\n",
    "\n",
    "# Print the filename\n",
    "print(f\"The filename for index {sample_index} is: {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8ecc67a-9fa0-4652-a9f9-4708d0f0ff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for age for sample 0: [0.37400037 0.11687841 0.50912124]\n",
      "Probabilities for gender for sample 0: [0.2918719 0.7081281]\n"
     ]
    }
   ],
   "source": [
    "specific_age_probs = predicted_age_probs[sample_index]\n",
    "specific_gender_probs = predicted_gender_probs[sample_index]\n",
    "\n",
    "print(f\"Probabilities for age for sample {sample_index}: {specific_age_probs}\")\n",
    "print(f\"Probabilities for gender for sample {sample_index}: {specific_gender_probs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507dbd83-3929-4694-b9f9-2ccfa1d9a299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ebcd0e-c702-43a7-8471-31c0aed1ced3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
