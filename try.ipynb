{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8cc4a0-8921-4de5-bce7-938027060746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install librosa numpy pandas scikit-learn tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709940ef-b94c-4785-a929-5efa7fcd96a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e47c6226-e56d-40d0-9495-9415b112b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e6f3a6-451b-4d73-9758-26fc3d45b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b2d746-f22a-4418-b6c2-8ac86727a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './track-2-audio-identification-quest/training_split/training_split'\n",
    "test_dir = './track-2-audio-identification-quest/testing_split/testing_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e888bd16-2182-4445-a60f-3b9e92274197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_files(dir_name):\n",
    "    list_of_files = os.listdir(dir_name)\n",
    "    all_files = []\n",
    "    for entry in list_of_files:\n",
    "        full_path = os.path.join(dir_name, entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            all_files.extend(get_list_of_files(full_path))\n",
    "        else:\n",
    "            all_files.append(full_path)\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf6916e8-27e2-4b12-afa1-4e79ac9421b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 1453\n",
      "Number of testing files: 637\n"
     ]
    }
   ],
   "source": [
    "# Get list of files\n",
    "train_files = get_list_of_files(train_dir)\n",
    "test_files = get_list_of_files(test_dir)\n",
    "\n",
    "print(f\"Number of training files: {len(train_files)}\")\n",
    "print(f\"Number of testing files: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f5de90c-9b36-4d86-8073-72447cbda4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio sample shape: (441000,)\n",
      "Sample rate: 44100\n"
     ]
    }
   ],
   "source": [
    "# Load a sample audio file\n",
    "sample_file = train_files[0]  # Just picking the first training file for now\n",
    "audio, sr = librosa.load(sample_file, sr=None)  # sr=None to keep the original sample rate\n",
    "\n",
    "print(f\"Audio sample shape: {audio.shape}\")\n",
    "print(f\"Sample rate: {sr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eb27260-97c6-4c37-98f2-227cadca42aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFCC features shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "def extract_mfcc(file_path, n_mfcc=20):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfccs, axis=1)  # Averaging over time\n",
    "\n",
    "# Extract MFCC features for a sample file\n",
    "mfcc_features = extract_mfcc(sample_file)\n",
    "print(f\"MFCC features shape: {mfcc_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4da23-118c-445c-bb74-3f850f71348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_files(file_paths, feature_extractor):\n",
    "    features = []\n",
    "    for file_path in file_paths:\n",
    "        feature = feature_extractor(file_path)\n",
    "        features.append(feature)\n",
    "    return np.array(features)\n",
    "\n",
    "# Extract features for training and testing files\n",
    "X_train = extract_features_from_files(train_files, extract_mfcc)\n",
    "X_test = extract_features_from_files(test_files, extract_mfcc)\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cffa57-f858-4d3e-ab39-129e39f7a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_labels_from_filename(filename):\n",
    "    # Example filename: '132_70_female.wav'\n",
    "    print(f\"Processing filename:{filename}\")\n",
    "    match = re.search(r'(\\d+)_([\\d]+)_(male|female)_(\\d+)\\.wav', filename)\n",
    "    if match:\n",
    "        age = int(match.group(2))\n",
    "        gender = match.group(3)\n",
    "        \n",
    "        # Determine age label\n",
    "        if age <= 15:\n",
    "            age_label = 0\n",
    "        elif 16 <= age <= 40:\n",
    "            age_label = 1\n",
    "        else:\n",
    "            age_label = 2\n",
    "        \n",
    "        # Determine gender label\n",
    "        gender_label = 0 if gender == 'male' else 1\n",
    "        \n",
    "        return age_label, gender_label\n",
    "    else:\n",
    "        raise ValueError(\"Filename does not match expected format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828201d-cf27-4708-b3be-368ac13674bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels_from_files(file_paths):\n",
    "    age_labels = []\n",
    "    gender_labels = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            age_label, gender_label = extract_labels_from_filename(os.path.basename(file_path))\n",
    "            age_labels.append(age_label)\n",
    "            gender_labels.append(gender_label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            \n",
    "    return np.array(age_labels), np.array(gender_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4628b1-8bf0-453b-9827-97cc5bd22789",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_age, y_train_gender = extract_labels_from_files(train_files)\n",
    "\n",
    "print(f\"Training age labels shape: {y_train_age.shape}\")\n",
    "print(f\"Training gender labels shape: {y_train_gender.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00656fd3-e760-4ba6-b79b-2a2c4c9133ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation features shape: (233, 13)\n",
      "Validation age labels shape: (233,)\n",
      "Validation gender labels shape: (233,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "X_train, X_val, y_train_age, y_val_age, y_train_gender, y_val_gender = train_test_split(\n",
    "    X_train, y_train_age, y_train_gender, test_size=0.2, random_state=42\n",
    ")\n",
    "#meaning age labels that i have made classified now\n",
    "print(f\"Validation features shape: {X_val.shape}\")\n",
    "print(f\"Validation age labels shape: {y_val_age.shape}\")\n",
    "print(f\"Validation gender labels shape: {y_val_gender.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "370e13ed-c543-4f01-907c-0ba4712c5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a11bbba-e23c-4f1a-8136-58340253500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Input\n",
    "\n",
    "# Define the model\n",
    "input_layer = Input(shape=(X_train.shape[1], 1))\n",
    "x = Conv1D(32, 3, activation='relu')(input_layer)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# Define two separate output layers\n",
    "age_output = Dense(3, activation='softmax', name='age_output')(x)\n",
    "gender_output = Dense(2, activation='softmax', name='gender_output')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[age_output, gender_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'age_output': 'sparse_categorical_crossentropy', 'gender_output': 'sparse_categorical_crossentropy'},\n",
    "    metrics={'age_output': 'accuracy', 'gender_output': 'accuracy'}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fcd1a852-44fd-4100-9aec-a7e1b6f7f244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_40\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_40\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_10              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │ flatten_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ age_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gender_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_10              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ conv1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ max_pooling1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m10,304\u001b[0m │ flatten_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ age_output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 │             \u001b[38;5;34m195\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gender_output (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │             \u001b[38;5;34m130\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,757</span> (42.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,757\u001b[0m (42.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,757</span> (42.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,757\u001b[0m (42.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16fc6290-0385-4cb7-816d-96186321102b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(929, 13, 1)\n",
      "(233, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "#reshaping\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print(X_train.shape)  \n",
    "print(X_val.shape)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f2184-ba92-4003-ae56-5cbda9bfcf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    {'age_output': y_train_age, 'gender_output': y_train_gender},\n",
    "    epochs=10,  \n",
    "    batch_size=32,  \n",
    "    validation_data=(X_val, {'age_output': y_val_age, 'gender_output': y_val_gender}),\n",
    "    verbose=1  # Set to 1 to see progress during training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b823736-b223-4a90-8c08-a4a2a1a9a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for test files\n",
    "X_test = extract_features_from_files(test_files, extract_mfcc)\n",
    "X_test = scaler.transform(X_test)  # Apply the same scaling as training data\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))  # Reshape for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d886d75-16ef-49b1-807f-378761d4de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test files: 637\n",
      "Shape of X_test: (637, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of test files: {len(test_files)}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "184860fc-4fa2-4480-8770-dce2d97b9531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test: (637, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b54f36e2-085f-4dbd-bd84-9e985add604a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test, batch_size=32)   #637/32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e5518bd0-08c0-4ae8-ad65-aa6ca80ace3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Predict age and gender for test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Extract the predicted class probabilities\n",
    "predicted_age_probs = predictions[0]\n",
    "predicted_gender_probs = predictions[1]\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_age_labels = np.argmax(predicted_age_probs, axis=1)\n",
    "predicted_gender_labels = np.argmax(predicted_gender_probs, axis=1)\n",
    "\n",
    "# Print some predictions to check\n",
    "print(predicted_age_labels[:10])  # Print first 10 predictions\n",
    "print(predicted_gender_labels[:10])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36212ed-cf1a-4114-8fb6-6d6643499bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Redefine the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'File_name': [os.path.basename(file) for file in test_files],\n",
    "    'Age_group': predicted_age_labels,\n",
    "    'Gender': ['Male' if gender == 0 else 'Female' for gender in predicted_gender_labels]\n",
    "})\n",
    "\n",
    "\n",
    "print(f\"Number of rows in DataFrame: {len(df)}\")\n",
    "\n",
    "# Print the first few rows to check the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7da55c71-ed13-44a3-a16f-432642858bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = 'predictions2.csv'\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06394d42-117e-4fdf-a7c7-9e8eb811502f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
