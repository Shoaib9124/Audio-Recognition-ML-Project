{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8cc4a0-8921-4de5-bce7-938027060746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install librosa numpy pandas scikit-learn tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709940ef-b94c-4785-a929-5efa7fcd96a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c6226-e56d-40d0-9495-9415b112b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6f3a6-451b-4d73-9758-26fc3d45b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2d746-f22a-4418-b6c2-8ac86727a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './track-2-audio-identification-quest/training_split/training_split'\n",
    "test_dir = './track-2-audio-identification-quest/testing_split/testing_split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e888bd16-2182-4445-a60f-3b9e92274197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_files(dir_name):\n",
    "    list_of_files = os.listdir(dir_name)\n",
    "    all_files = []\n",
    "    for entry in list_of_files:\n",
    "        full_path = os.path.join(dir_name, entry)\n",
    "        if os.path.isdir(full_path):\n",
    "            all_files.extend(get_list_of_files(full_path))\n",
    "        else:\n",
    "            all_files.append(full_path)\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6916e8-27e2-4b12-afa1-4e79ac9421b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of files\n",
    "train_files = get_list_of_files(train_dir)\n",
    "test_files = get_list_of_files(test_dir)\n",
    "\n",
    "print(f\"Number of training files: {len(train_files)}\")\n",
    "print(f\"Number of testing files: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5de90c-9b36-4d86-8073-72447cbda4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample audio file\n",
    "sample_file = train_files[0]  # Just picking the first training file for now\n",
    "audio, sr = librosa.load(sample_file, sr=None)  # sr=None to keep the original sample rate\n",
    "\n",
    "print(f\"Audio sample shape: {audio.shape}\")\n",
    "print(f\"Sample rate: {sr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb27260-97c6-4c37-98f2-227cadca42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(file_path, n_mfcc=13):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "    return np.mean(mfccs, axis=1)  # Averaging over time\n",
    "\n",
    "# Extract MFCC features for a sample file\n",
    "mfcc_features = extract_mfcc(sample_file)\n",
    "print(f\"MFCC features shape: {mfcc_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4da23-118c-445c-bb74-3f850f71348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_files(file_paths, feature_extractor):\n",
    "    features = []\n",
    "    for file_path in file_paths:\n",
    "        feature = feature_extractor(file_path)\n",
    "        features.append(feature)\n",
    "    return np.array(features)\n",
    "\n",
    "# Extract features for training and testing files\n",
    "X_train = extract_features_from_files(train_files, extract_mfcc)\n",
    "X_test = extract_features_from_files(test_files, extract_mfcc)\n",
    "\n",
    "print(f\"Training features shape: {X_train.shape}\")\n",
    "print(f\"Testing features shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cffa57-f858-4d3e-ab39-129e39f7a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_labels_from_filename(filename):\n",
    "    # Example filename: '132_70_female.wav'\n",
    "    print(f\"Processing filename:{filename}\")\n",
    "    match = re.search(r'(\\d+)_([\\d]+)_(male|female)_(\\d+)\\.wav', filename)\n",
    "    if match:\n",
    "        age = int(match.group(2))\n",
    "        gender = match.group(3)\n",
    "        \n",
    "        # Determine age label\n",
    "        if age <= 15:\n",
    "            age_label = 0\n",
    "        elif 16 <= age <= 40:\n",
    "            age_label = 1\n",
    "        else:\n",
    "            age_label = 2\n",
    "        \n",
    "        # Determine gender label\n",
    "        gender_label = 0 if gender == 'male' else 1\n",
    "        \n",
    "        return age_label, gender_label\n",
    "    else:\n",
    "        raise ValueError(\"Filename does not match expected format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828201d-cf27-4708-b3be-368ac13674bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels_from_files(file_paths):\n",
    "    age_labels = []\n",
    "    gender_labels = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            age_label, gender_label = extract_labels_from_filename(os.path.basename(file_path))\n",
    "            age_labels.append(age_label)\n",
    "            gender_labels.append(gender_label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            \n",
    "    return np.array(age_labels), np.array(gender_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4628b1-8bf0-453b-9827-97cc5bd22789",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_age, y_train_gender = extract_labels_from_files(train_files)\n",
    "\n",
    "print(f\"Training age labels shape: {y_train_age.shape}\")\n",
    "print(f\"Training gender labels shape: {y_train_gender.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00656fd3-e760-4ba6-b79b-2a2c4c9133ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split training data into training and validation sets\n",
    "X_train, X_val, y_train_age, y_val_age, y_train_gender, y_val_gender = train_test_split(\n",
    "    X_train, y_train_age, y_train_gender, test_size=0.2, random_state=42\n",
    ")\n",
    "#meaning age labels that i have made classified now\n",
    "print(f\"Validation features shape: {X_val.shape}\")\n",
    "print(f\"Validation age labels shape: {y_val_age.shape}\")\n",
    "print(f\"Validation gender labels shape: {y_val_gender.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e13ed-c543-4f01-907c-0ba4712c5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and validation data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a11bbba-e23c-4f1a-8136-58340253500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the model\n",
    "input_layer = Input(shape=(X_train.shape[1], 1))\n",
    "x = Conv1D(32, 3, activation='relu')(input_layer)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# Define two separate output layers\n",
    "age_output = Dense(3, activation='softmax', name='age_output')(x)\n",
    "gender_output = Dense(2, activation='softmax', name='gender_output')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[age_output, gender_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss={'age_output': 'sparse_categorical_crossentropy', 'gender_output': 'sparse_categorical_crossentropy'},\n",
    "    metrics={'age_output': 'accuracy', 'gender_output': 'accuracy'}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcd1a852-44fd-4100-9aec-a7e1b6f7f244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_3               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ age_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gender_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_3               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ max_pooling1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m10,304\u001b[0m │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ age_output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                 │             \u001b[38;5;34m195\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gender_output (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │             \u001b[38;5;34m130\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,757</span> (42.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,757\u001b[0m (42.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,757</span> (42.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,757\u001b[0m (42.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16fc6290-0385-4cb7-816d-96186321102b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 13, 1)\n",
      "(291, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "#reshaping\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print(X_train.shape)  \n",
    "print(X_val.shape)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "787f2184-ba92-4003-ae56-5cbda9bfcf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - age_output_accuracy: 0.4632 - age_output_loss: 1.0467 - gender_output_accuracy: 0.3689 - gender_output_loss: 0.7481 - loss: 1.7949 - val_age_output_accuracy: 0.7457 - val_age_output_loss: 0.9179 - val_gender_output_accuracy: 0.5533 - val_gender_output_loss: 0.6907 - val_loss: 1.5871\n",
      "Epoch 2/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.7606 - age_output_loss: 0.8588 - gender_output_accuracy: 0.6397 - gender_output_loss: 0.6582 - loss: 1.5172 - val_age_output_accuracy: 0.7526 - val_age_output_loss: 0.7871 - val_gender_output_accuracy: 0.6873 - val_gender_output_loss: 0.6322 - val_loss: 1.3976\n",
      "Epoch 3/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.7703 - age_output_loss: 0.7121 - gender_output_accuracy: 0.6923 - gender_output_loss: 0.6123 - loss: 1.3243 - val_age_output_accuracy: 0.7526 - val_age_output_loss: 0.6975 - val_gender_output_accuracy: 0.7045 - val_gender_output_loss: 0.5965 - val_loss: 1.2720\n",
      "Epoch 4/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.7679 - age_output_loss: 0.6260 - gender_output_accuracy: 0.7060 - gender_output_loss: 0.5876 - loss: 1.2132 - val_age_output_accuracy: 0.7526 - val_age_output_loss: 0.6392 - val_gender_output_accuracy: 0.7045 - val_gender_output_loss: 0.5761 - val_loss: 1.1924\n",
      "Epoch 5/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.7859 - age_output_loss: 0.5568 - gender_output_accuracy: 0.7004 - gender_output_loss: 0.5711 - loss: 1.1280 - val_age_output_accuracy: 0.7560 - val_age_output_loss: 0.6010 - val_gender_output_accuracy: 0.7045 - val_gender_output_loss: 0.5629 - val_loss: 1.1404\n",
      "Epoch 6/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.7677 - age_output_loss: 0.5176 - gender_output_accuracy: 0.7162 - gender_output_loss: 0.5494 - loss: 1.0670 - val_age_output_accuracy: 0.7629 - val_age_output_loss: 0.5763 - val_gender_output_accuracy: 0.7045 - val_gender_output_loss: 0.5528 - val_loss: 1.1035\n",
      "Epoch 7/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - age_output_accuracy: 0.7773 - age_output_loss: 0.5129 - gender_output_accuracy: 0.7221 - gender_output_loss: 0.5300 - loss: 1.0427 - val_age_output_accuracy: 0.7766 - val_age_output_loss: 0.5596 - val_gender_output_accuracy: 0.7045 - val_gender_output_loss: 0.5446 - val_loss: 1.0790\n",
      "Epoch 8/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8013 - age_output_loss: 0.4699 - gender_output_accuracy: 0.7296 - gender_output_loss: 0.5257 - loss: 0.9957 - val_age_output_accuracy: 0.7835 - val_age_output_loss: 0.5479 - val_gender_output_accuracy: 0.7045 - val_gender_output_loss: 0.5377 - val_loss: 1.0605\n",
      "Epoch 9/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8191 - age_output_loss: 0.4453 - gender_output_accuracy: 0.7166 - gender_output_loss: 0.5296 - loss: 0.9748 - val_age_output_accuracy: 0.7869 - val_age_output_loss: 0.5403 - val_gender_output_accuracy: 0.7079 - val_gender_output_loss: 0.5321 - val_loss: 1.0464\n",
      "Epoch 10/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.7912 - age_output_loss: 0.4666 - gender_output_accuracy: 0.7509 - gender_output_loss: 0.5050 - loss: 0.9718 - val_age_output_accuracy: 0.7801 - val_age_output_loss: 0.5324 - val_gender_output_accuracy: 0.7113 - val_gender_output_loss: 0.5280 - val_loss: 1.0355\n",
      "Epoch 11/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - age_output_accuracy: 0.8105 - age_output_loss: 0.4450 - gender_output_accuracy: 0.7504 - gender_output_loss: 0.5015 - loss: 0.9465 - val_age_output_accuracy: 0.7766 - val_age_output_loss: 0.5281 - val_gender_output_accuracy: 0.7285 - val_gender_output_loss: 0.5231 - val_loss: 1.0271\n",
      "Epoch 12/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - age_output_accuracy: 0.8277 - age_output_loss: 0.4263 - gender_output_accuracy: 0.7568 - gender_output_loss: 0.4946 - loss: 0.9213 - val_age_output_accuracy: 0.7698 - val_age_output_loss: 0.5232 - val_gender_output_accuracy: 0.7285 - val_gender_output_loss: 0.5189 - val_loss: 1.0185\n",
      "Epoch 13/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - age_output_accuracy: 0.8275 - age_output_loss: 0.4205 - gender_output_accuracy: 0.7674 - gender_output_loss: 0.4768 - loss: 0.8974 - val_age_output_accuracy: 0.7595 - val_age_output_loss: 0.5187 - val_gender_output_accuracy: 0.7285 - val_gender_output_loss: 0.5157 - val_loss: 1.0115\n",
      "Epoch 14/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - age_output_accuracy: 0.8270 - age_output_loss: 0.4114 - gender_output_accuracy: 0.7639 - gender_output_loss: 0.4904 - loss: 0.9019 - val_age_output_accuracy: 0.7560 - val_age_output_loss: 0.5158 - val_gender_output_accuracy: 0.7285 - val_gender_output_loss: 0.5137 - val_loss: 1.0069\n",
      "Epoch 15/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8142 - age_output_loss: 0.4204 - gender_output_accuracy: 0.7719 - gender_output_loss: 0.4820 - loss: 0.9029 - val_age_output_accuracy: 0.7560 - val_age_output_loss: 0.5131 - val_gender_output_accuracy: 0.7388 - val_gender_output_loss: 0.5103 - val_loss: 1.0024\n",
      "Epoch 16/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8391 - age_output_loss: 0.3769 - gender_output_accuracy: 0.7886 - gender_output_loss: 0.4545 - loss: 0.8313 - val_age_output_accuracy: 0.7526 - val_age_output_loss: 0.5084 - val_gender_output_accuracy: 0.7423 - val_gender_output_loss: 0.5075 - val_loss: 0.9967\n",
      "Epoch 17/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8375 - age_output_loss: 0.3938 - gender_output_accuracy: 0.7719 - gender_output_loss: 0.4851 - loss: 0.8788 - val_age_output_accuracy: 0.7560 - val_age_output_loss: 0.5057 - val_gender_output_accuracy: 0.7320 - val_gender_output_loss: 0.5065 - val_loss: 0.9944\n",
      "Epoch 18/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8387 - age_output_loss: 0.3827 - gender_output_accuracy: 0.7707 - gender_output_loss: 0.4640 - loss: 0.8463 - val_age_output_accuracy: 0.7560 - val_age_output_loss: 0.5028 - val_gender_output_accuracy: 0.7285 - val_gender_output_loss: 0.5028 - val_loss: 0.9894\n",
      "Epoch 19/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - age_output_accuracy: 0.8249 - age_output_loss: 0.4049 - gender_output_accuracy: 0.7653 - gender_output_loss: 0.4868 - loss: 0.8921 - val_age_output_accuracy: 0.7560 - val_age_output_loss: 0.4993 - val_gender_output_accuracy: 0.7354 - val_gender_output_loss: 0.5028 - val_loss: 0.9869\n",
      "Epoch 20/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - age_output_accuracy: 0.8360 - age_output_loss: 0.3815 - gender_output_accuracy: 0.7659 - gender_output_loss: 0.4757 - loss: 0.8573 - val_age_output_accuracy: 0.7560 - val_age_output_loss: 0.4968 - val_gender_output_accuracy: 0.7388 - val_gender_output_loss: 0.4996 - val_loss: 0.9824\n",
      "Epoch 21/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8193 - age_output_loss: 0.3989 - gender_output_accuracy: 0.7775 - gender_output_loss: 0.4601 - loss: 0.8590 - val_age_output_accuracy: 0.7595 - val_age_output_loss: 0.4940 - val_gender_output_accuracy: 0.7526 - val_gender_output_loss: 0.5000 - val_loss: 0.9811\n",
      "Epoch 22/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8271 - age_output_loss: 0.3911 - gender_output_accuracy: 0.7800 - gender_output_loss: 0.4688 - loss: 0.8601 - val_age_output_accuracy: 0.7560 - val_age_output_loss: 0.4907 - val_gender_output_accuracy: 0.7491 - val_gender_output_loss: 0.4975 - val_loss: 0.9774\n",
      "Epoch 23/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8263 - age_output_loss: 0.3769 - gender_output_accuracy: 0.7986 - gender_output_loss: 0.4307 - loss: 0.8077 - val_age_output_accuracy: 0.7560 - val_age_output_loss: 0.4893 - val_gender_output_accuracy: 0.7526 - val_gender_output_loss: 0.4951 - val_loss: 0.9742\n",
      "Epoch 24/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8181 - age_output_loss: 0.3785 - gender_output_accuracy: 0.8051 - gender_output_loss: 0.4345 - loss: 0.8132 - val_age_output_accuracy: 0.7595 - val_age_output_loss: 0.4865 - val_gender_output_accuracy: 0.7526 - val_gender_output_loss: 0.4958 - val_loss: 0.9730\n",
      "Epoch 25/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8305 - age_output_loss: 0.3716 - gender_output_accuracy: 0.7828 - gender_output_loss: 0.4514 - loss: 0.8230 - val_age_output_accuracy: 0.7560 - val_age_output_loss: 0.4849 - val_gender_output_accuracy: 0.7560 - val_gender_output_loss: 0.4933 - val_loss: 0.9706\n",
      "Epoch 26/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8500 - age_output_loss: 0.3531 - gender_output_accuracy: 0.8014 - gender_output_loss: 0.4381 - loss: 0.7913 - val_age_output_accuracy: 0.7595 - val_age_output_loss: 0.4806 - val_gender_output_accuracy: 0.7526 - val_gender_output_loss: 0.4910 - val_loss: 0.9650\n",
      "Epoch 27/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8345 - age_output_loss: 0.3609 - gender_output_accuracy: 0.8070 - gender_output_loss: 0.4266 - loss: 0.7877 - val_age_output_accuracy: 0.7595 - val_age_output_loss: 0.4792 - val_gender_output_accuracy: 0.7629 - val_gender_output_loss: 0.4920 - val_loss: 0.9655\n",
      "Epoch 28/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8368 - age_output_loss: 0.3654 - gender_output_accuracy: 0.8053 - gender_output_loss: 0.4146 - loss: 0.7802 - val_age_output_accuracy: 0.7663 - val_age_output_loss: 0.4780 - val_gender_output_accuracy: 0.7663 - val_gender_output_loss: 0.4900 - val_loss: 0.9622\n",
      "Epoch 29/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - age_output_accuracy: 0.8312 - age_output_loss: 0.3601 - gender_output_accuracy: 0.8080 - gender_output_loss: 0.4278 - loss: 0.7877 - val_age_output_accuracy: 0.7663 - val_age_output_loss: 0.4758 - val_gender_output_accuracy: 0.7698 - val_gender_output_loss: 0.4900 - val_loss: 0.9597\n",
      "Epoch 30/30\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - age_output_accuracy: 0.8147 - age_output_loss: 0.3856 - gender_output_accuracy: 0.8142 - gender_output_loss: 0.4219 - loss: 0.8075 - val_age_output_accuracy: 0.7663 - val_age_output_loss: 0.4731 - val_gender_output_accuracy: 0.7629 - val_gender_output_loss: 0.4897 - val_loss: 0.9580\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    {'age_output': y_train_age, 'gender_output': y_train_gender},\n",
    "    epochs=30,  \n",
    "    batch_size=32,  \n",
    "    validation_data=(X_val, {'age_output': y_val_age, 'gender_output': y_val_gender}),\n",
    "    verbose=1  # Set to 1 to see progress during training\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b823736-b223-4a90-8c08-a4a2a1a9a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for test files\n",
    "X_test = extract_features_from_files(test_files, extract_mfcc)\n",
    "X_test = scaler.transform(X_test)  # Apply the same scaling as training data\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))  # Reshape for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d886d75-16ef-49b1-807f-378761d4de01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test files: 637\n",
      "Shape of X_test: (637, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of test files: {len(test_files)}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "184860fc-4fa2-4480-8770-dce2d97b9531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test: (637, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b54f36e2-085f-4dbd-bd84-9e985add604a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test, batch_size=32)   #637/32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5518bd0-08c0-4ae8-ad65-aa6ca80ace3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Predict age and gender for test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Extract the predicted class probabilities\n",
    "predicted_age_probs = predictions[0]\n",
    "predicted_gender_probs = predictions[1]\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_age_labels = np.argmax(predicted_age_probs, axis=1)\n",
    "predicted_gender_labels = np.argmax(predicted_gender_probs, axis=1)\n",
    "\n",
    "# Print some predictions to check\n",
    "print(predicted_age_labels[:10])  # Print first 10 predictions\n",
    "print(predicted_gender_labels[:10])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c36212ed-cf1a-4114-8fb6-6d6643499bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in DataFrame: 637\n",
      "  File_name  Age_group  Gender\n",
      "0     1.wav          1    Male\n",
      "1    10.wav          1    Male\n",
      "2  1000.wav          1    Male\n",
      "3   106.wav          1  Female\n",
      "4   107.wav          1    Male\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Redefine the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'File_name': [os.path.basename(file) for file in test_files],\n",
    "    'Age_group': predicted_age_labels,\n",
    "    'Gender': ['Male' if gender == 0 else 'Female' for gender in predicted_gender_labels]\n",
    "})\n",
    "\n",
    "\n",
    "print(f\"Number of rows in DataFrame: {len(df)}\")\n",
    "\n",
    "# Print the first few rows to check the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7da55c71-ed13-44a3-a16f-432642858bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_path = 'predictions3.csv'\n",
    "df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06394d42-117e-4fdf-a7c7-9e8eb811502f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
